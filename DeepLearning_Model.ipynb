{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnW/0YIHXhWhnlV0t+e+sc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankesh86/PySparkNotebooks/blob/main/DeepLearning_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Building a Multilayer Perceptron Model**"
      ],
      "metadata": {
        "id": "rQ0HTQbrqqk0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5FHnQ7_qkgs",
        "outputId": "620ef34f-aa0a-490c-93f8-1042f168cabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.4.0\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.4.0) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317122 sha256=27942c7e87b7cd6cda130ddc77df92882100eb65e7ff15ca65d55a8a0b910024\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('deep_learning').getOrCreate()"
      ],
      "metadata": {
        "id": "78VTzbmrq-lV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the Libraries**"
      ],
      "metadata": {
        "id": "LKSCnx9esq0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "HptzXLywsdj5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the files"
      ],
      "metadata": {
        "id": "aye9CfTMs66z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.csv('sample_data/dl_data.csv', header=True, inferSchema=True)\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrE4Wr8Bs57W",
        "outputId": "696bc60e-101f-4022-d264-ecda0a4ef8a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Visit_Number_Bucket: string (nullable = true)\n",
            " |-- Page_Views_Normalized: double (nullable = true)\n",
            " |-- Orders_Normalized: integer (nullable = true)\n",
            " |-- Internal_Search_Successful_Normalized: double (nullable = true)\n",
            " |-- Internal_Search_Null_Normalized: double (nullable = true)\n",
            " |-- Email_Signup_Normalized: double (nullable = true)\n",
            " |-- Total_Seconds_Spent_Normalized: double (nullable = true)\n",
            " |-- Store_Locator_Search_Normalized: double (nullable = true)\n",
            " |-- Mapped_Last_Touch_Channel: string (nullable = true)\n",
            " |-- Mapped_Mobile_Device_Type: string (nullable = true)\n",
            " |-- Mapped_Browser_Type: string (nullable = true)\n",
            " |-- Mapped_Entry_Pages: string (nullable = true)\n",
            " |-- Mapped_Site_Section: string (nullable = true)\n",
            " |-- Mapped_Promo_Code: string (nullable = true)\n",
            " |-- Maped_Product_Name: string (nullable = true)\n",
            " |-- Mapped_Search_Term: string (nullable = true)\n",
            " |-- Mapped_Product_Collection: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformation of Data**"
      ],
      "metadata": {
        "id": "cNvhPJO0tdko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.withColumnRenamed('Orders_Normalized','label')\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFyRNd8YtJSt",
        "outputId": "f1e1fbde-9301-4068-c49a-4e16832af8dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Visit_Number_Bucket: string (nullable = true)\n",
            " |-- Page_Views_Normalized: double (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- Internal_Search_Successful_Normalized: double (nullable = true)\n",
            " |-- Internal_Search_Null_Normalized: double (nullable = true)\n",
            " |-- Email_Signup_Normalized: double (nullable = true)\n",
            " |-- Total_Seconds_Spent_Normalized: double (nullable = true)\n",
            " |-- Store_Locator_Search_Normalized: double (nullable = true)\n",
            " |-- Mapped_Last_Touch_Channel: string (nullable = true)\n",
            " |-- Mapped_Mobile_Device_Type: string (nullable = true)\n",
            " |-- Mapped_Browser_Type: string (nullable = true)\n",
            " |-- Mapped_Entry_Pages: string (nullable = true)\n",
            " |-- Mapped_Site_Section: string (nullable = true)\n",
            " |-- Mapped_Promo_Code: string (nullable = true)\n",
            " |-- Maped_Product_Name: string (nullable = true)\n",
            " |-- Mapped_Search_Term: string (nullable = true)\n",
            " |-- Mapped_Product_Collection: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline to change categorical to numerical"
      ],
      "metadata": {
        "id": "S6jRcvPvudRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf, StringType\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier"
      ],
      "metadata": {
        "id": "RSI2nRY8trr9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, validation, test = data.randomSplit([0.7, 0.2, 0.1], 1234)"
      ],
      "metadata": {
        "id": "EUMmw-MZt_v4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = [item[0] for item in data.dtypes if item[1].startswith('string')]\n",
        "numeric_columns = [item[0] for item in data.dtypes if item[1].startswith('double')]\n",
        "\n",
        "indexers = [StringIndexer(inputCol=column, outputCol='{0}_index'.format(column)) for column in categorical_columns]\n",
        "\n",
        "featuresCreator = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numeric_columns, outputCol=\"features\")\n"
      ],
      "metadata": {
        "id": "Aqma1oNhuuxy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layers\n",
        "The layers parameter is an array of integers where each integer represents the number of neurons in a layer. The way you have structured the layers array is as follows:\n",
        "\n",
        "* First element: This represents the number of input neurons, which should match the number of features in your input dataset. In your code, featuresCreator.\n",
        "* getInputCols() suggests that the first layer's size is dynamically set based on the number of input columns transformed by featuresCreator.\n",
        "* Intermediate elements: These elements specify the number of neurons in each hidden layer. In your example, 4 and 2 are the sizes of the two hidden layers. The hidden layers are where the model learns the non-linear relationships between the features and the label.\n",
        "* Last element: This represents the number of output neurons, which should match the number of classes in a classification problem (for binary classification, it is often set to 2). Each output corresponds to a class score that, after transformation, can be interpreted as a probability.\n",
        "* Other Configurable Parameters\n",
        "In addition to layers, there are several other parameters in\n",
        "\n",
        "### MultilayerPerceptronClassifier that you can configure:\n",
        "\n",
        "* labelCol: The name of the column in the dataset that contains the label to predict.\n",
        "* featuresCol: The name of the column in the dataset that contains the feature vector.\n",
        "* maxIter: The maximum number of iterations to train the network. More iterations might allow the network to converge to a better solution but also take longer to compute.\n",
        "* blockSize: The size of the block of input data to process at once. This is used to control memory usage and optimization of the calculations.\n",
        "* seed: A seed for random number generation. This helps in creating reproducibility in your experiments."
      ],
      "metadata": {
        "id": "QEpfv1sYySGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [len(featuresCreator.getInputCols()), 4, 2, 2]\n",
        "classifier = MultilayerPerceptronClassifier(labelCol='label', featuresCol='features', maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
        "pipeline = Pipeline(stages=indexers + [featuresCreator, classifier])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t5f5iFD3wx_3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fit the model**"
      ],
      "metadata": {
        "id": "cm3Aw82_0kE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(train)"
      ],
      "metadata": {
        "id": "pjn3G-CU0hbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Calculating the predictions**"
      ],
      "metadata": {
        "id": "Ud6Te7Rxz94w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_output_df = model.transform(train)\n",
        "validation_output_df = model.transform(validation)\n",
        "test_output_df = model.transform(test)"
      ],
      "metadata": {
        "id": "YVTG2qTEziqh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluate the Predictions**"
      ],
      "metadata": {
        "id": "yqV7b-yc0uTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictionAndLabels = train_output_df.select(\"prediction\", \"label\")\n",
        "validation_predictionAndLabels = validation_output_df.select(\"prediction\", \"label\")\n",
        "test_predictionAndLabels = test_output_df.select(\"prediction\", \"label\")\n",
        "\n",
        "metrics = ['weightedPrecision', 'weightedRecall', 'accuracy']\n",
        "\n",
        "for metric in metrics:\n",
        "    evaluator = MulticlassClassificationEvaluator(metricName=metric)\n",
        "    print('Train ' + metric + ' = ' + str(evaluator.evaluate(train_predictionAndLabels)))\n",
        "    print('Validation ' + metric + ' = ' + str(evaluator.evaluate(validation_predictionAndLabels)))\n",
        "    print('Test ' + metric + ' = ' + str(evaluator.evaluate(test_predictionAndLabels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f286bFl-0sK3",
        "outputId": "3729a5d8-28ec-451b-adfd-8c637e5d82e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train weightedPrecision = 0.9702977504063095\n",
            "Validation weightedPrecision = 0.9700372050939752\n",
            "Test weightedPrecision = 0.9678924180434567\n",
            "Train weightedRecall = 0.9698878326626621\n",
            "Validation weightedRecall = 0.9696474751599292\n",
            "Test weightedRecall = 0.9673558215451578\n",
            "Train accuracy = 0.9698878326626621\n",
            "Validation accuracy = 0.9696474751599292\n",
            "Test accuracy = 0.9673558215451578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJstJGbx2UhE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}