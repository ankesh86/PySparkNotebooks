{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEciNhGSLEI7dIxDfBUVrT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankesh86/PySparkNotebooks/blob/main/SupervisedML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt5UL2qKcHrN",
        "outputId": "46bc5f4c-e444-4e7f-edb2-f961a3d0493c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.4.0\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.4.0) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317122 sha256=1e8aa2441d0f8b840e85a909aa2e290f123375f50082a310499838caf764a7e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion"
      ],
      "metadata": {
        "id": "FbS2zm7rcoy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Create Spark session object"
      ],
      "metadata": {
        "id": "94vc3S8ccs5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear_regression_dataset.csv\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('supervised_ml').getOrCreate()"
      ],
      "metadata": {
        "id": "S8HHXl7VcTC4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Reading the Dataset"
      ],
      "metadata": {
        "id": "w4UBjRDadFR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('sample_data/Linear_regression_dataset.csv', inferSchema=True, header=True)\n",
        "print((df.count(), len(df.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5CJPwUYdEX-",
        "outputId": "34b6295e-70d4-422a-ac01-0b6362742af8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1232, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9SYvL4gdr3y",
        "outputId": "c5807236-50dd-4e31-8606-71343eeee28d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- var_1: integer (nullable = true)\n",
            " |-- var_2: integer (nullable = true)\n",
            " |-- var_3: integer (nullable = true)\n",
            " |-- var_4: double (nullable = true)\n",
            " |-- var_5: double (nullable = true)\n",
            " |-- label: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSeoaRumeLI1",
        "outputId": "6f25f600-53c4-425e-dbd3-5b8c74013880"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----+-----+-----+-----+\n",
            "|var_1|var_2|var_3|var_4|var_5|label|\n",
            "+-----+-----+-----+-----+-----+-----+\n",
            "|  734|  688|   81|0.328|0.259|0.418|\n",
            "|  700|  600|   94| 0.32|0.247|0.389|\n",
            "|  712|  705|   93|0.311|0.247|0.417|\n",
            "|  734|  806|   69|0.315| 0.26|0.415|\n",
            "|  613|  759|   61|0.302| 0.24|0.378|\n",
            "|  748|  676|   85|0.318|0.255|0.422|\n",
            "|  669|  588|   97|0.315|0.251|0.411|\n",
            "|  667|  845|   68|0.324|0.251|0.381|\n",
            "|  758|  890|   64| 0.33|0.274|0.436|\n",
            "|  726|  670|   88|0.335|0.268|0.422|\n",
            "+-----+-----+-----+-----+-----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Feature Engineering"
      ],
      "metadata": {
        "id": "1fD_HzW8ekcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOOfBdRVeY50",
        "outputId": "c479c11c-3aa4-495d-cc71-305c44b38b7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'label']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_assembler = VectorAssembler(inputCols=['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'label'], outputCol='features')\n",
        "features_df = vec_assembler.transform(df)\n"
      ],
      "metadata": {
        "id": "wjerCTAAfAdP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN9GiRjWfSgo",
        "outputId": "50f44fae-03dc-44a7-c02c-6a1582bb9929"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- var_1: integer (nullable = true)\n",
            " |-- var_2: integer (nullable = true)\n",
            " |-- var_3: integer (nullable = true)\n",
            " |-- var_4: double (nullable = true)\n",
            " |-- var_5: double (nullable = true)\n",
            " |-- label: double (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzhCcC1KfZr8",
        "outputId": "f57e5aec-c2ab-4151-ad37-805b68e574c4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----+-----+-----+-----+\n",
            "|var_1|var_2|var_3|var_4|var_5|label|\n",
            "+-----+-----+-----+-----+-----+-----+\n",
            "|  734|  688|   81|0.328|0.259|0.418|\n",
            "|  700|  600|   94| 0.32|0.247|0.389|\n",
            "|  712|  705|   93|0.311|0.247|0.417|\n",
            "|  734|  806|   69|0.315| 0.26|0.415|\n",
            "|  613|  759|   61|0.302| 0.24|0.378|\n",
            "|  748|  676|   85|0.318|0.255|0.422|\n",
            "|  669|  588|   97|0.315|0.251|0.411|\n",
            "|  667|  845|   68|0.324|0.251|0.381|\n",
            "|  758|  890|   64| 0.33|0.274|0.436|\n",
            "|  726|  670|   88|0.335|0.268|0.422|\n",
            "+-----+-----+-----+-----+-----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.select('features','label').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btjV6INuf1Un",
        "outputId": "9d16003a-e4e4-4163-ead3-061e38acf29b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[734.0,688.0,81.0...|0.418|\n",
            "|[700.0,600.0,94.0...|0.389|\n",
            "|[712.0,705.0,93.0...|0.417|\n",
            "|[734.0,806.0,69.0...|0.415|\n",
            "|[613.0,759.0,61.0...|0.378|\n",
            "|[748.0,676.0,85.0...|0.422|\n",
            "|[669.0,588.0,97.0...|0.411|\n",
            "|[667.0,845.0,68.0...|0.381|\n",
            "|[758.0,890.0,64.0...|0.436|\n",
            "|[726.0,670.0,88.0...|0.422|\n",
            "|[583.0,794.0,55.0...|0.371|\n",
            "|[676.0,746.0,72.0...|  0.4|\n",
            "|[767.0,699.0,89.0...|0.433|\n",
            "|[637.0,597.0,86.0...|0.374|\n",
            "|[609.0,724.0,69.0...|0.382|\n",
            "|[776.0,733.0,83.0...|0.437|\n",
            "|[701.0,832.0,66.0...| 0.39|\n",
            "|[650.0,709.0,74.0...|0.386|\n",
            "|[804.0,668.0,95.0...|0.453|\n",
            "|[713.0,614.0,94.0...|0.404|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 : Splitting the Dataset"
      ],
      "metadata": {
        "id": "aChTO9gghenx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df.randomSplit([0.75,0.25])\n",
        "print(f\"Size of train Dataset : {train.count()}\")\n",
        "print(f\"Size of test Dataset : {test.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQZZ6XmGgbGG",
        "outputId": "4cefc3d9-c522-42ae-d112-cf0ad5b1475e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train Dataset : 936\n",
            "Size of test Dataset : 296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Build and Train Linear Regression Model"
      ],
      "metadata": {
        "id": "uk9gnpJ_iTUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression()\n",
        "\n",
        "lr_model = lr.fit(train)\n",
        "\n",
        "prediction_df = lr_model.transform(test)\n",
        "prediction_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "kj_enrcxiLup",
        "outputId": "12c83c53-ef10-4294-be7b-d216f1a09044"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "features does not exist. Available: var_1, var_2, var_3, var_4, var_5, label",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a8e2dc6457b3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprediction_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: features does not exist. Available: var_1, var_2, var_3, var_4, var_5, label"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Evaluate Linear Regression Model"
      ],
      "metadata": {
        "id": "q-P5vsoSkAYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_predictions = lr_model.evaluate(test)\n",
        "model_predictions.r2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8ylmf0si8ay",
        "outputId": "03eb2615-95f9-480d-8478-71a31c7d8c6f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_predictions.meanSquaredError)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRiw1yEukOt2",
        "outputId": "73efa835-e17d-4401-d11b-010945c29ae2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.542724230651031e-29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Fit the model\n",
        "lr_model = lr.fit(train)\n",
        "\n",
        "# Make predictions\n",
        "prediction_df = lr_model.transform(test)\n",
        "\n",
        "# Show predictions\n",
        "prediction_df.select(\"features\", \"label\", \"prediction\").show()\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Calculate RMSE (Root Mean Squared Error)\n",
        "rmse = evaluator.evaluate(prediction_df)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
        "\n",
        "# You can change the metricName to \"r2\", \"mae\", etc., to evaluate those as well\n",
        "r2 = evaluator.evaluate(prediction_df, {evaluator.metricName: \"r2\"})\n",
        "print(\"R-squared (R2) on test data = %g\" % r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKvTLMHhk4TQ",
        "outputId": "37d96e24-ae6a-411f-e6b1-eda7d76f60d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-------------------+\n",
            "|            features|label|         prediction|\n",
            "+--------------------+-----+-------------------+\n",
            "|[464.0,640.0,66.0...|0.301| 0.3010000000000124|\n",
            "|[468.0,746.0,52.0...|0.329|0.32899999999999796|\n",
            "|[486.0,610.0,61.0...|0.332|0.33199999999999885|\n",
            "|[495.0,752.0,50.0...|0.327| 0.3270000000000184|\n",
            "|[498.0,615.0,67.0...|0.318| 0.3180000000000089|\n",
            "|[498.0,672.0,61.0...|0.325|0.32500000000001156|\n",
            "|[510.0,588.0,72.0...|0.317|0.31700000000000605|\n",
            "|[514.0,549.0,81.0...|0.339|0.33899999999998726|\n",
            "|[516.0,504.0,86.0...|0.327| 0.3270000000000057|\n",
            "|[519.0,595.0,73.0...|0.332|0.33199999999999746|\n",
            "|[524.0,665.0,65.0...|0.336|0.33600000000000996|\n",
            "|[528.0,652.0,71.0...|0.319|0.31900000000000617|\n",
            "|[532.0,690.0,69.0...|0.351|0.35099999999998815|\n",
            "|[550.0,631.0,76.0...|0.318| 0.3180000000000083|\n",
            "|[554.0,536.0,77.0...|0.339| 0.3390000000000032|\n",
            "|[556.0,674.0,62.0...|0.348|  0.348000000000005|\n",
            "|[559.0,613.0,75.0...|0.359|0.35900000000000304|\n",
            "|[568.0,708.0,57.0...|0.347|0.34700000000000164|\n",
            "|[569.0,620.0,77.0...|0.349| 0.3490000000000048|\n",
            "|[570.0,578.0,82.0...|0.363| 0.3629999999999992|\n",
            "+--------------------+-----+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Root Mean Squared Error (RMSE) on test data = 9.76869e-15\n",
            "R-squared (R2) on test data = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generalized Linear Model Regression**"
      ],
      "metadata": {
        "id": "WYX2zK8OmeBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Build and Train Generalized Linear Regression Model"
      ],
      "metadata": {
        "id": "wsQL5CUAnnLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "glr = GeneralizedLinearRegression()\n",
        "glr_model = glr.fit(train)\n",
        "\n",
        "glr_model.coefficients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW6w0LohmWTP",
        "outputId": "731ec44f-f1a0-4671-de1b-e9dfed43fb68"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([0.0, -0.0, -0.0, -0.0, 0.0, 1.0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9SCYWmMoOlz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}